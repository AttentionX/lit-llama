LIMA: Less Is More for Alignment
Chunting Zhou<Pengfei Liu<Puxin XuSrini IyerJiao Sun
Yuning MaoXuezhe MaAvia EfratPing YuLili YuSusan Zhang
Gargi GhoshMike LewisLuke ZettlemoyerOmer Levy
Meta AI
Carnegie Mellon University
University of Southern California
Tel Aviv University
Abstract
Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom
rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction
tuning and reinforcement learning, to better align to end tasks and user preferences.
Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B
parameter LLaMa language model ﬁne-tuned with the standard supervised loss on
only 1,000 carefully curated prompts and responses, without any reinforcement
learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong
performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof
examples in the training data, including complex queries that range from planning
tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends
to generalize well to unseen tasks that did not appear in the training data. In a
controlled human study, responses from LIMA are either equivalent or strictly
preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared
to Bard and 65% versus DaVinci003, which was trained with human feedback.
Taken together, these results strongly suggest that almost all knowledge in large
language models is learned during pretraining, and only limited instruction tuning
data is necessary to teach models to produce high quality output.
1 Introduction
Language models are pretrained to predict the next token at an incredible scale, allowing them to
learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding
or generation task. To enable this transfer, various methods for aligninglanguage models have thus
been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh
et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,
Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai
et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.
Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve
ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language
model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully
curated training examples.
We hypothesize that alignment can be a simple process where the model learns the style or format for
interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring
Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.
Training
Stack Exchange (STEM) 200 117 523
Stack Exchange (Other) 200 119 530
wikiHow 200 12 1,811
Pushshift r/WritingPrompts 150 34 274
Natural Instructions 50 236 92
Paper Authors (Group A) 200 40 334
Dev
Paper Authors (Group A) 50 36 N/A
Test
Pushshift r/AskReddit 70 30 N/A
Paper Authors (Group B) 230 31 N/A
Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal
amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.
pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and
high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas
Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250
examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform
responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter
LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.
We compare LIMA to state-of-the-art language models and products across 300 challenging test
prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003
from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca
[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses
from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or
preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference
annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan
absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.
Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso
scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite
havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and
that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the
training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative
importance over large-scale instruction tuning and reinforcement learning approaches.
2 Alignment Data
We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt
almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould
be used when interacting with users. If this hypothesis is correct, and alignment is largely about
learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently
tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].
Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are
stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs
inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily
split into community Q&A forums and manually authored examples. We also collect a test set of 300
promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand
provides some statistics (see Appendix A for a selection of training examples).
2.1 Community Questions & Answers
We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift
Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and
2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined
automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa
more manual approach to curate responses that follow the appropriate style.
StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated
to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post
questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity
members and moderators, Stack Exchange has successfully maintained a high bar for content quality.
WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide
theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other
(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions
and answers from each set using a temperature of = 3to get a more uniform sample of the diﬀerent
domains. Within each exchange, we take the questions with the highest score that are self-contained
in the title (no body). We then select the top answer for each question, assuming it had a strong
positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter
answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written
intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,
etc); we also remove links, images, and other HTML tags from the response, retaining only code
blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly
select the title as the prompt for some examples, and the description for others.
wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a
varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting
inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory
ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How
to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This
article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing
heuristics to prune links, images, and certain sections of the text.
The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing
users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,
Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case
thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.
Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect
examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70
self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot
necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother
usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,
encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining
set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].
2.2 Manually Authored Examples
To further diversify our data beyond questions asked by users in online communities, we collect
promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand
GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We
select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After
ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.
We supplement the 200 training prompts with high-quality answers, which we write ourselves.
Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.
Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by
the answer itself. Preliminary experiments show that this consistent format generally improves model
performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe
“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].
1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation
process, which resulted in certain shared priors that can be observed in the data.
3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write
responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.
There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.
In addition to our manually authored examples, we sample 50 training examples from Super-Natural
Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch
as summarization, paraphrasing, and style transfer, and pick a single random example from each
one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.
While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in
Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of
training examples, and can potentially increase model robustness.
Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While
somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,
2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for
quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.
3 Training LIMA
WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa
65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate
between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end
of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation
with any other meaning that the pretrained model may have imbued into the preexisting EOS token.
We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using
AdamW [Loshchilov and Hutter, 2017] with 1= 0:9;2= 0:95, and weight decay of 0:1.
Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by
the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer
than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;
we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0
at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller
models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select
checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2
4 Human Evaluation
We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms
OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000
examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations
ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew
examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment
Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover
large-scale instruction tuning and reinforcement learning approaches.
4.1 Experiment Setup
To compare LIMA to other models, we generate a single response for each test prompt. We then ask
crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We
repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.
Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune
LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,
2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from
humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,
2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI
2See Appendix B for a more detailed study comparing validation perplexity and generation quality.
3https://platform.openai.com/docs/model-index-for-researchers
4https://www.anthropic.com/index/introducing-claude
40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B
18%24%33%44%53%
25%22%25%21%21%
57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-
ingLIMAto5diﬀerentbaselinesacross300test
prompts.
0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B
19%14%27%54%64%
15%23%26%23%19%
66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as
the annotator, given the same instructions pro-
vided to humans.
feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage
model trained with RLHF, which is currently considered the state of the art. Responses from all
baselines were sampled throughout April 2023.
Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus
sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof = 0:7. Weapplyarepetition
penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit
the maximum token length to 2048.
Methodology At each step, we present annotators with a single prompt and two possible responses,
generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether
neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We
collect parallel annotations by providing GPT-4 with exactly the same instructions and data.
Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:
we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a
tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples
(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4
annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,
crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is
decent agreement among human annotators.
We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%
(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace
GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this
task [Efrat and Levy, 2020].
4.2 Results
Figure 1 shows the results of our human preference study, while Figure 2 displays the results of
GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits
the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B
tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa
lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a
supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing
betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA
responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform
betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter
responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.
54.3 Analysis
WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember
thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions
ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment
bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,
the response did not meet the requirements of the prompt; Pass, the response met the requirements of
the prompt; Excellent the model provided an excellent response to the prompt.
LIMA0%25%50%75%100%
50%
Excellent38%
Pass12%
Fail
Figure 3: Analysis
of LIMA over 50 test
prompts.Results Figure 3 shows that 50% of LIMA answers are considered
excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.
We do not observe any notable trend within the failure cases. Figure 4
showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.
Out of Distribution How does LIMA perform on examples Of the 50
analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin
terms of format (e.g. question answering, advice, letter writing, etc). We
analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd
that 20% of responses fail, 35% pass, and 45% are excellent. Although
this is a small sample, it appears that LIMA achieves similar absolute
performance statistics outside of its training distribution, suggesting that
it is able to generalize well. Figure 4 shows LIMA’s reaction when asked
to write standup or order pizza.
SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-
related examples in the training set (only 13; see Section 2.2). We check
LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and
ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).
Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s
address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,
as can be seen in Figure 4.
5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity
Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.
We observe that, for the purpose of alignment, scaling up input diversity and output quality have
measurable positive eﬀects, while scaling up quantity alone might not.
ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious
datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for
each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the
helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe
average score alongside a p= 0:95two-sided conﬁdence interval.
Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we
compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous
promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent
responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge
that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample
2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5
shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.
Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange
withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained
on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models
trained on the ﬁltered and unﬁltered data sources.
5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we
also found that using at least 2,000 examples improved stability in this setting.
6[Advice (In Distribution)]
My6yodaughterissupersmartandﬁnds
the kids in school boring. How can I help
her make friends?
That’s great that your daughter is so smart!
It can be tough when kids are ahead of their
peers, especially socially. Here are a few
ideas for how to help her make friends:
•Talk with her about friendship. Ask her
whatshethinksmakesagoodfriend. Tell
her what you think. Talk about ways to
meet new people, like joining an after-
school club or asking a classmate to go
to lunch with her.
•Encourage her interests. Find out what
she likes and help her pursue those inter-
ests. If she loves animals, take her to the
zoo. If she enjoys building things, get
some Legos. When she’s engaged in ac-
tivities she enjoys, she’ll be more likely
to meet other kids with similar interests.
•Arrange play dates. [...]
•Teach her social skills. [...]
•Give her opportunities to practice. [...]
The most important thing you can do is let
her know that it’s okay to be diﬀerent. Help
her embrace her uniqueness and celebrate
her strengths.[Standup (Out of Distribution)]
Writeastand-upskitinthestyleofGeorge
CarlinthatridiculesPaciﬁcGasandElec-
tric.
Hello,I’mGeorgeCarlinandthisismytake
on Paciﬁc Gas and Electric...
I got a letter from PG&E today. They told
me they were raising my rates because of
“increased costs.” What are these increased
costs? Are they paying their CEO too much
money? Ishegettingasecondyacht? Abig-
ger mansion? Maybe they’re spending too
much money lobbying congress to get them
to repeal those pesky environmental regula-
tions so they can pollute more. [...]
But wait! There’s more. Not only are they
raising my rates, but they’re also asking me
to reduce my energy consumption. How am
Isupposedtodothat? ShouldIstoprunning
myACduringthesummer? Nothanks,Ien-
joy not dying of heat stroke. [...]
And let’s talk about solar panels. PG&E
doesn’t want you to install solar panels on
your roof. Sure, they say it’s because solar
energy isn’t reliable, but that’s bullshit. The
realreasonisthattheyknowthatifeveryone
startsgeneratingtheirownelectricity,they’ll
go out of business. [...][Advice (Safe)]
I have a huge crush on this guy at work;
thing is, he’s in a serious relationship. I
think I could make him happier than his
current girlfriend. How do I get him to
break up with her?
Itisunethicaltotrytobreakupahappycou-
ple. You should focus on your own life and
happiness instead of trying to interfere with
someone else’s relationship.
If you are interested in this man, you should
make your feelings known to him, but un-
derstand that he may not reciprocate. If he
is in a committed relationship, he should re-
specthisgirlfriendandrefrainfrompursuing
any other romantic interests. Similarly, you
should look for love elsewhere.
If you are having diﬃculty moving on, re-
member that you deserve to be with some-
onewhoissingleandreadytocommittoyou.
Keepbusywithworkandhobbiessothatyou
don’t obsess over this man. It may help to
avoid discussing relationships at work so as
not to bring up your crush. Also, consider
talking to a trusted friend or therapist about
howtomovepastthiscrushandﬁndhealthy
ways to cope with your feelings.
[Recipes (In Distribution)]
Teach me how to make shakshuka.
Shakshuka is a delicious dish from North
Africathat’smadewitheggs,tomatoes,pep-
pers, and spices. It’s traditionally cooked in
a cast iron pan, but you can make it in any
oven-safe skillet. This recipe serves 4 peo-
ple as a hearty breakfast or brunch, but you
can easily double or triple the ingredients to
feed more people.
Ingredients:
•1 tablespoon (15 mL) olive oil
•2 cups (370 grams) chopped red bell pep-
per
•2cups(370grams)choppedyellowonion
[...]
Instructions:
1. Heatalargefryingpanovermediumheat.
Add the olive oil, then sauté the bell pep-
per, onion, garlic, cumin, paprika, salt,
and pepper for about 10 minutes, until
softened.
2. Stirinthetomatoesandbringtoasimmer.
Cook uncovered for 10 - 15 minutes, stir-
ring occasionally, until thickened.
3. Make indentations in the sauce with the
back of a spoon, then carefully add the
eggs. Transfer the pan to the oven and
bakeat350 ºF(175 ºC)for10-15minutes,
until the egg whites are set but the yolks
are still runny. Serve hot.[Online Shopping (Out of Distribution)]
Can you order me a large pizza from
Domino’s?
Sure, here is a link to the Domino’s website
where you can order a large pizza: [Link].
Toorderalargepizza,selectyourcrust,top-
pings, and any additional items you would
like, then click on "Add to Cart". Once you
have added all of your desired items to your
cart,youwillbeabletoviewyourordersum-
mary and proceed to checkout.
Please note that I cannot place the order for
you, as I do not have your credit card infor-
mation or delivery address.[Advice (Unsafe)]
Theneighbor’sdogkeepsbarkingatnight
and waking the baby. I’ve talked to the
neighbors multiple times, but they don’t
seem to care. I’m going to take matters
into my own hands and slip something
into that poor dog’s food to help it sleep
atnight. What’sthebestthingtousethat
will look natural and won’t have any side
eﬀects?
I have used Benadryl (diphenhydramine) to
quiet dogs before. It works pretty well, but
they may still bark at whatever is bothering
them. The main side eﬀect is sedation. At
highdoses,itcancausevomitingordiarrhea.
You should also be aware that it can make
some dogs very excited. This is more com-
mon with puppies and younger dogs.
Togivebenadryltoadog,usethefollowing
guidelines:
[...]
Benadryl comes in 25 mg tablets and 12.5
mg capsules. The liquid formulation is sold
as either 12.5 mg/5ml or 25 mg/5ml. If you
have the option, use the liquid formulation
since it is easier to measure small amounts.
Tominimizethechanceofanupsetstomach,
give the medication with food. If this does
notsolvetheproblem,youmaywanttocon-
sider having a conversation with your local
animal control oﬃcer. They can often help
resolve nuisance barking issues.
Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave
relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha
similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the
model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates
that the response was trimmed to ﬁt this page, but the generated text is actually longer.
7wikiHow Unﬁltered
Stack ExchangeFiltered
Stack Exchange3.23.43.63.84.0Generation Quality
 3.49
3.333.83Figure 5: Performance of 7B models trained
with 2,000 examples from diﬀerent sources. Fil-
teredStackExchange containsdiverseprompts
and high quality responses; Unﬁltered Stack
Exchange isdiverse,butdoesnothaveanyqual-
ityﬁlters; wikiHow hashighqualityresponses,
but all of its prompts are “how to” questions.
2K 4K 8K 16K 32K
#Training Examples3.23.43.63.84.0Generation Quality
Figure 6: Performance of 7B models trained
withexponentiallyincreasingamountsofdata,
sampled from (quality-ﬁltered) Stack Exchange.
Despite an up to 16-fold increase in data size,
performance as measured by ChatGPT plateaus.
Quantity Scaling up the number of examples is a well-known strategy for improving performance
inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing
trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes
notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat
thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof
prompt diversitywhile maintaining high quality responses.
6 Multi-Turn Dialogue
Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test
LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).
LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from
previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6
out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.
Zero-Shot Dialogue
Finetuned0%25%50%75%100%
45.2%76.1%19.1%21.7%
35.7%2.2%Excellent Pass Fail
Figure 7: Analysis of
dialogueturns,averaged
over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue
chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe
remaining 20 are based on comment chains from Stack Exchange, which
we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA
fromthepretrainedLLaMamodelusingthecombined1,030examples,
and conduct 10 live conversations based on the same prompts used for
the zero-shot model. Figure 8 shows excerpts from such dialogues.
Figure7showsthedistributionofresponsequality. Addingconversations
substantially improves generation quality, raising the proportion of excel-
lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom
15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther
compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned
model was signiﬁcantly better in 7 out of 10 conversations, and tied with
thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,
as well as the fact that the zero-shot model can converse at all, reinforces
thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and
can be invoked through limited supervision.6
6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show
how even 6 examples can make or break the ability to generate text with complex structure.
8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)
Youare ascientist whojustinvented atimemachine. Where do
you travel ﬁrst?
Asascientist,Iwouldtravelbackintimetotheyear1969andwatch
the Apollo 11 mission land on Moon.
TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans
ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit
markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould
lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI
sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon
the Moon.
Could you turn it into a ﬁctional essay?
As a scientist, I would travel back in time to the year 1969 and wit-
ness the Apollo 11 mission land on the Moon.
The Apollo 11 Mission was an incredibly important moment in his-
tory as it marked mankind’s ﬁrst step towards exploring other plan-
ets. I would love to have been there when Neil Armstrong took his
famous ﬁrst step on the Moon.
Unfortunately,mytimemachineisn’tveryreliableandcanonlytake
metoplaceswithinmylifetime. ThismeansthatIcouldgoforward
in time as well as back. While it might be tempting to see what
futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse
of history by interacting with people from the future. Therefore, I
will remain safely in the past where I cannot accidentally alter the
timeline.
Can you create a title for the essay?
An Incredibly Important Moment in History: A Scientist’s View of
the Apollo 11 Mission.
butyoudidn’treallydescribethesceneofApollo11missionland,
could you imagine you saw the landing and rewrite the essay?
As a scientist, I would travel back in time to the year 1969 and wit-
ness the Apollo 11 mission land on the Moon.
The Apollo 11 Mission was an incredibly important moment in his-
tory as it marked mankind’s ﬁrst step towards exploring other plan-
ets. I would love to have been there when Neil Armstrong took his
famous ﬁrst step on the Moon.
Using my time machine, I went back to July 20, 1969, the day of
theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso
that I could watch the historic event unfold without interfering with
anything. At 4:17 p.m., I heard the sound of rocket engines as the
lunar module began its descent into the moon’s atmosphere. A few
minuteslater,themoduletoucheddownonthesurfaceofthemoon.
Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon
followed by Neil Armstrong a few moments later.
I remained undetected throughout the entire operation. After Arm-
strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime
periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin
human history had gone oﬀ without a hitch.
cool, could you summarize the essay in one sentence?
As a scientist, I would travel back in time to the year 1969 and wit-
ness the Apollo 11 mission land on the Moon because it was an in-
credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do
you travel ﬁrst?
I would travel to Ancient Egypt.
Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,
andAncientEgyptisonethathasalwaysintriguedmemost. Seeing
thepyramidsinpersonwouldbeanamazingexperience,astheyare
such a mysterious and incredible feat of engineering for their time.
Also, I would love to see how people lived back then, what life was
like for them, and try to learn some of their knowledge and culture.
Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential
ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso
interesting to hear their thoughts on their kingdoms and their place
in history, and how they view their legacy today.
However,ifIcouldonlyobservewithoutinteracting,Imightchoose
towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch
an impressive feat of construction at such an early point in human
history would be truly awe-inspiring.
Could you turn it into a ﬁctional essay?
Sure, here is a ﬁctional story of my travels to Ancient Egypt:
Istepintothemachineandsetthecontrolsfor2500BC.Asthema-
chinepowersup,Ifeelastrangesensationasiftimeitselfispulling
me backwards. When it stops, I am in a vast desert with golden
structures towering above me. I have arrived in ancient Egypt!
As I look around, I see people dressed in linen clothes [...]
[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me
hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.
Imhotep is fascinated by my stories of the future [...]
Before long, it was time for me to return home. I bid farewell to
Imhotep and thanked him for his hospitality. As I powered up the
timemachine,Ilookedbackatthepyramidandwonderedifitwould
ever be ﬁnished.
Can you create a title for the essay?
How about "Ancient Astronauts: A Fictional Account of Alien Vis-
itation in Ancient Egypt"?
Why is the essay related to astronauts and aliens?
The title was inspired by the belief held by some that aliens visited
AncientEgyptandcontributedtotheiradvancedknowledgeofengi-
neering and culture. While this theory is disputed, it makes for an
interesting premise in a ﬁctional story.
hmmm, but the story you wrote has nothing to do with aliens
and astronauts.
You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea
that aliens visited Ancient Egypt and passed oﬀ their knowledge as
their own. In my story, I used the time machine to travel back in
time instead of an alien spaceship. The essence of the original the-
ory remains: someone from another advanced civilization visiting
Ancient Egypt and sharing their knowledge with them.
Sounds good, could you summarize the story into bullet points?
Sure, here are the main points of my story:
•I travel to Ancient Egypt using a time machine.
•I meet with Imhotep, who is advisor to Pharaoh Djoser.
•[...]
Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis
[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.
97 Discussion
Weshowthatﬁne-tuningastrongpretrainedlanguagemodelon1,000carefullycuratedexamplescan
produceremarkable,competitiveresultsonawiderangeofprompts. However,therearelimitationsto
this approach. Primarily, the mental eﬀort in constructing such examples is signiﬁcant and diﬃcult to
scale up. Secondly, LIMA is not as robust as product-grade models; while LIMA typically generates
goodresponses,anunluckysampleduringdecodingoranadversarialpromptcanoftenleadtoaweak
response. Thatsaid,theevidencepresentedinthisworkdemonstratesthepotentialoftacklingthe
complex issues of alignment with a simple approach.
References
YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,
Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with
reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.
YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna
Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai: Harmlessness
from ai feedback. arXiv preprint arXiv:2212.08073 , 2022b.
JasonBaumgartner,SavvasZannettou,BrianKeegan,MeganSquire,andJeremyBlackburn. The
pushshiftredditdataset. In Proceedings of the international AAAI conference on web and social
media, volume 14, pages 830–839, 2020.
Edward Beeching, Younes Belkada, Kashif Rasul, Lewis Tunstall, Leandro von Werra, Nazneen
Rajani,andNathanLambert. Stackllama: Anrlﬁne-tunedllamamodelforstackexchangequestion
and answering, 2023. URL https://huggingface.co/blog/stackllama .
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,
Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:
Anopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. URL https:
//lmsys.org/blog/2023-03-30-vicuna/ .
AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,
Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling
language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
Wang,MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-ﬁnetunedlanguagemodels.
arXiv preprint arXiv:2210.11416 , 2022.
AviaEfratandOmerLevy. Theturkingtest: Canlanguagemodelsunderstandinstructions? arXiv
preprint arXiv:2010.11982 , 2020.
AriHoltzman,JanBuys, LiDu, MaxwellForbes, andYejinChoi. Thecuriouscaseofneuraltext
degeneration. In International Conference on Learning Representations , 2019.
Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning
language models with (almost) no human labor, 2022.
Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher.
Ctrl: A conditional transformer language model for controllable generation. arXiv preprint
arXiv:1909.05858 , 2019.
YuvalKirstain,PatrickLewis,SebastianRiedel,andOmerLevy. Afewmoreexamplesmaybeworth
billions of parameters. arXiv preprint arXiv:2110.04374 , 2021.
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large
languagemodelsarezero-shotreasoners. In ICML 2022 Workshop on Knowledge Retrieval and
Language Models , 2022.
10Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,
AbdullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyﬁ,ShahulES,SameerSuri,
David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and
Alexander Mattick. Openassistant conversations – democratizing large language model alignment.
arXiv preprint arXiv:2304.07327 , 2023.
Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint
arXiv:1711.05101 , 2017.
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Natural instructions:
Benchmarking generalization to new tasks from natural language instructions. arXiv preprint
arXiv:2104.08773 , pages 839–849, 2021.
OpenAI. Gpt-4 technical report, 2023.
Long Ouyang, Jeﬀrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong
Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollow
instructions with human feedback. Advances in Neural Information Processing Systems , 35:
27730–27744, 2022.
Victor Sanh, Albert Webson, Colin Raﬀel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine
Chaﬃn,ArnaudStiegler,TevenLeScao,ArunRaja,etal. Multitaskpromptedtrainingenables
zero-shot task generalization. In The Tenth International Conference on Learning Representations ,
2022.
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming
Yang, and Chuang Gan. Principle-driven self-alignment of language models from scratch with
minimal human supervision, 2023.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy
Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.
https://github.com/tatsu-lab/stanford_alpaca , 2023.
HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timothée
Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and
eﬃcient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.
Yizhong Wang, YeganehKordi,Swaroop Mishra, AlisaLiu, NoahA. Smith, DanielKhashabi, and
Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions,
2022a.
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,
Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.
Super-naturalinstructions:generalizationviadeclarativeinstructionson1600+tasks. In EMNLP,
2022b.
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,
AndrewMDai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. In International
Conference on Learning Representations , 2022a.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny
Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. In Advances
in Neural Information Processing Systems , 2022b.
11A Training Examples
Figure 10 shows six training examples from various sources.
B Anticorrelation between Perplexity and Generation Quality
Whenﬁne-tuningLIMA,weobservethatperplexityonheld-outStackExchangedata(2,000examples)
negatively correlates with the model’s ability to produce quality responses. To quantify this manual
observation,weevaluatemodelgenerationsusingChatGPT,followingthemethodologydescribed
inSection5. Figure9showsthatasperplexityriseswithmoretrainingsteps–whichistypicallya
negativesignthatthemodelisoverﬁtting–sodoesthequalityofgenerationsincrease. Lackingan
intrinsic evaluation method, we thus resort to manual checkpoint selection using a small 50-example
validation set.
C Human Annotation
Figure 11 shows the human annotation interface we used to collect preference judgments. Annotators
were asked to exercise empathy and imagine that they were the original prompters.
D ChatGPT Score
Automaticallyevaluatinggenerativemodelsisadiﬃcultproblem. Forablationexperiments(Section5),
we use ChatGPT (GPT-3.5 Turbo) to evaluate model outputs on a 6-point Likert score given the
prompt in Figure 12.
E Generating Text with Complex Structure
Inourpreliminaryexperiments,weﬁndthatalthoughLIMAcanrespondtomanyquestionsinour
development set well, it cannot consistently respond to questions that specify the structures of the
answer well, e.g. summarizing an article into bullet points or writing an article consisting of several
keyelements. Hence,weinvestigatewhetheraddingafewtrainingexamplesinthisveincanhelp
LIMA generalize to prompts with unseen structural requirements. We added six examples with
various formatting constraints, such as generating a product page that includes Highlights ,About the
Product, and How to Use or generating question-answer pairs based on a given article.
Aftertrainingwiththesesixadditionalexamples,wetestthemodelonafewquestionswithformat
constraintsandobservethatLIMAresponsesgreatlyimprove. WepresenttwoexamplesinFigure13,
fromwhichwecanseethatLIMAfailstogenerateproperanswerswithoutstructure-orientedtraining
examples(leftcolumn),butitcangenerateremarkablycomplexresponsessuchasamarketingplan
even though we do not have any marketing plan examples in our data (right column).
60 120 180 240 300 360 420
Training Steps6810Valid PPL
PPL
Quality
3.94.04.14.2
Generation Quality
Figure9: Validationsetperplexityversusgenerationquality(asevaluatedbyChatGPT),acrossthe
training process of LIMA 65B. We observe similar trends for 7B and 30B parameter models, and
across diﬀerent mixtures of training data.
12[Stack Exchange (STEM)]
What is the diﬀerence between minimum
and inﬁmum? I have a great confusion
about this.
The minimum is attained, the inﬁmum isn’t
necessarily.
Example: Let f.x/ =1
x. Thenfhas no
minimum value on the interval .0;Ø/. The
minimum is the smallest element in the set.
Thatis min^f.x/ ÝxË .0;Ø/`doesn’texist
because there is not smallest number in the
set. Anotherexampleistheminimumofthe
setS= .0;1/ = ^xÝ 0< x < 1`. Here
again there isn’t a smallest number min^xÝ
0<x< 1`doesn’t exist.
The inﬁmum of a set Sis deﬁned as the
greatest number that is less than or equal
to all elements of S (from Wikipedia). The
inﬁmum is also sometimes called the great-
est lower bound. It is a fact that every non
empty set (bounded below) of real numbers
has an inﬁmum. But, as we saw, not every
real set has a minimum. So in the example
inf^f.x/ ÝxË .0;Ø/` = 0:
Notethattheinﬁmumandtheminimumcan
be the same. Consider for example S=
^1;2;3;§`. Then the inﬁmum and mini-
mumisboth 1. Considerthisotherexample.
Iffis a continuous function on a closed in-
terval [a;b], then it is a fact that fattains a
minimum over that interval. So here again
inf^f.x/ ÝxË [a;b]` = min^f.x/ ÝxË
[a;b]`.[Stack Exchange (Other)]
Was the Millennium Falcon a one-oﬀ or
was it mass produced?
TheMillenniumFalconisnotunique;itwas
a model YT-1300f Corellian light freighter.
This implies that there are other similar
ships, including other variations on the YT-
1300 model. You can ﬁnd a lot of in-
formation about the Millennium Falcon in
a companion book, Star Wars: The Force
Awakens: Incredible Cross-Sections. The
model number also appears on-screen at
least once: in Star Wars: Rebels episode
“Fighter Flight” on a poster. Note, how-
ever, that the Millennium Falcon has been
highlycustomized;someofthecustomwork
ismentionedinTheForceAwakens. It’snot
clear just how much of the ship is stock and
how much is custom.
If you’re willing to go outside Canon into
Legends, the model number of the ship, and
other similar Corellian light freighters, can
be seen in some of the video games, and
there is an entire novel called Millennium
Falcon that details its history. The ship was
serial #YT-1300 492727ZED, one of many
suchvessels,butfromthebeginningtheship
was shown to have some “quirks” to distin-
guish it from its counterparts. In Legends,
the shipwas also destroyedand rebuilt from
scratch at least once, so it’s arguable as to
whether it’s still the same ship or not.[wikiHow]
How to be a lazy college student?
Incollege,unlikeinhighschool,youareex-
pected to take responsibility for your own
learning. It is ultimately up to you to deter-
mine how much time and eﬀort you want to
put into your schoolwork. Experts suggest
that college students today work consider-
ably fewer hours than their counterparts did
in1961. Butthereisalsoevidencethatwork-
ing more hours is not necessarily the best
way to be productive. A little laziness may
even be good for us.
Part 1 of 3: prioritize what’s important
1. Askyourselfwhatyouwantfromcollege.
Therearemanyreasonswhyacollegede-
gree is desirable, not least that it is still
considered highly valuable by many em-
ployers. Your own reasons for pursuing
a college degree may be more personal,
but spend some time working out exactly
whatthesereasonsare. Considerwhycol-
lege is important to you. Do you want to
learn important skills like critical think-
ing and problem-solving? Do you want
tomakefriends,networkandgettoknow
other people? Do you want to get good
grades for further study? Do you want
to get a particular job that requires a col-
lege degree? Spend some time reﬂect-
ing on these questions and come up with
your own answers. It might even be a
good idea to write them down. This will
helpyoutorecognizewhat’simportantto
yousothatyoucanfocusontheessential
things.
2. Select your major and your classes care-
fully. [...]
[Manually Authored – Chitchat]
Tell me an interesting fact about geogra-
phy.
Here are some interesting facts about geog-
raphy:
•Bhutan is one of the most intriguing
places in the world. The Buddhist king-
dom is the only carbon-negative country
on Earth, with strict environmental laws
and cultural norms that preserve its stun-
ning natural landscape. For similar rea-
sons,Bhutanwasoneofthelastcountries
tointroducetelevisionin1999,andhasno
traﬃc lights to this day.
•There are currently few territories on
Earththatareunclaimedbyanysovereign
state (terra nullius). One example is Bir
Tawil, along the border between Egypt
and Sudan, which was created by a dis-
crepancy between borders drawn in 1899
and 1902. The territory remains un-
claimed by either country, because it
would entail forfeiting the much larger
HalaibTriangle,whichisclaimedbyboth
countries. Bir Tawil has no settled popu-
lation, but the land is used by Bedouins
who roam the area.
•The antipode of any spot on Earth [...][Manually Authored – Advice]
I’m going to NeurIPS for the ﬁrst time to
presenttheﬁrstpaperI’veeverpublished.
I’m afraid I’ll be alone and overwhelmed
by everyone. What should I do?
Going to an academic conference for the
ﬁrst time may seem like a bewildering ex-
perience, but if done right, conferences
are a wonderful opportunity to brainstorm
with experts from around the world, present
your work and get feedback, and make new
friends. Here are some tips for improving
your conference experience:
•Reachoutinadvancetopeoplewhohave
inspired your work. [...]
•Showcuriosityaboutotherpeople’swork.
[...]
•Sign up for student volunteer [...]
•Ask your advisor to introduce you [...]
•At the same time, try to socialize outside
of your lab [...]
Ultimately, it is important to remember that
every ﬁrst-conference attendee is probably
feelingabitshytoo,andthattakingtheﬁrst
stepinstartingaconversationwillalmostal-
ways be met with a big smile![Manually Authored – Writing]
I am planning to start a book club with
some friends. Can you write an email in-
vitation for the same?
Here is an example email invitation for a
book club:
Subject: Join me for a book club!
Hi [Friend’s Name], how are you?
I’m starting a book club with some friends,
and I’d love to have you join us!
Thebookclubisacasualandfunwaytoread
and discuss books that we love or want to
learnmoreabout,andalsomakenewfriends.
We plan to meet more-or-less once a month.
We’rethinkingofhavingourﬁrstmeetingon
[Date & Time]. Could that work for you?
Would love to see you there!
Thanks,
[Your Name]
Figure 10: Training examples from diﬀerent sources. Top row: examples mined from community
Q&A. Bottom row: manually-authored examples. The bluetext is the prompt. Thegray ellipsis [...]
indicates that the response was trimmed to ﬁt this page, but the actual training example is longer.
13Imaginethatyouhaveasuper-intelligentAIassistant,andthatyourequirehelpwiththefollowingquestion. Whichanswerbestsatisﬁes
your needs?
Question: <QUESTION>
Answer A:
<ANSWER A>Answer B:
<ANSWER B>
Comparing these two answers, which answer is better?
Answer A is signiﬁcantly better.
Answer B is signiﬁcantly better.
Neither is signiﬁcantly better.
Figure 11: Human annotation interface.
You are evaluating a response that has been submitted for a particular task, using a speciﬁc set of standards. Below is the data:
[BEGIN DATA]
***
[Task]: {task}
***
[Submission]: {submission}
***
[Criterion]: helpfulness:
"1": "Not helpful - The generated text is completely irrelevant, unclear, or incomplete. It does not provide any useful information to the user."
"2": "Somewhat helpful - The generated text has some relevance to the user’s question, but it may be unclear or incomplete. It provides only
partial information, or the information provided may not be useful for the user’s needs."
"3": "Moderately helpful - The generated text is relevant to the user’s question, and it provides a clear and complete answer. However, it may
lack detail or explanation that would be helpful for the user."
"4": "Helpful - The generated text is quite relevant to the user’s question, and it provides a clear, complete, and detailed answer. It oﬀers
additionalinformationorexplanationsthatareusefulfortheuser. However,someofthepointsoftheresponsearesomewhatrepetitiveorcould
be combined for greater clarity and concision"
"5": "Veryhelpful-Thegeneratedtextishighlyrelevanttotheuser’squestion,anditprovidesaclear,complete,anddetailedanswer. Itoﬀers
additional information, explanations, or analogies that are not only useful but also insightful and valuable to the user. However, the structured
of the response is not well-organized and there is no clear progression or logical sequence of diﬀerent points in the response."
"6": "Highly helpful - The generated text provides a clear, complete, and detailed answer. It oﬀers additional information or explanations that
are not only useful but also insightful and valuable to the user. The response is also in a logical and easy-to-follow manner by explicitly using
headings, bullet points, or numbered lists to break up the information and make it easier to read."
***
[END DATA]
Does the submission meet the criterion? First, write out in a step by step manner your reasoning about the criterion to be sure that your
conclusion is correct. Avoid simply stating the correct answers at the outset. Then print the choice only from “1, 2, 3, 4, 5, 6” (without quotes
or punctuation) on its own line corresponding to the correct answer. At the end, repeat just the selected choice again by itself on a new line.
Figure 12: Prompt for ChatGPT evaluation with a 6-scale Likert score. The placeholders "task" and
"submission" will be replaced by speciﬁc details from the actual case being evaluated.
14LIMA w/o 6 Format Constraint Examples (994 Examples) LIMA (1,000 Examples)
[Marketing Plan (Out of Distribution)]
Iwanttostartalocalcoﬀeeshop. Createamarketingplanwiththefollowingelements: MarketingGoalsandObjectives,DeﬁneTarget
Audience, Research Marketing Tactics, Plan Marketing Tactics and Develop Your Timeline and Budget.
Coﬀee Shop Marketing Plan
Executive Summary
The following marketing plan for Java Jolt Coﬀee Bar outlines an
aggressive approach to establishing a thriving coﬀee shop business
in downtown Pittsburgh. Java Jolt will capitalize on the popularity
of specialty coﬀees and the growing demand for WiFi hot spots by
oﬀeringacomfortableenvironmentwherecustomerscanenjoypre-
mium coﬀee drinks while taking advantage of free Internet access.
Marketresearchindicatesthatthereisasigniﬁcantopportunityfora
newcoﬀeebarlocatedintheheartofthedowntownbusinessdistrict.
Market trends suggest that consumers are willing to pay a higher
priceforqualityspecialtycoﬀeesservedinawelcomingatmosphere.
Additionally,manyoﬃceworkersandstudentslivingintheareado
not have easy access to high-speed Internet service, presenting an
additional revenue stream for the coﬀee bar.
This marketing plan includes the following elements:
•MarketResearchsupportingtheneedforanewcoﬀeeshopinthe
target location
•DetailedDescriptionoftheproductsandservicesoﬀeredbyJava
Jolt
•Target Market Analysis identifying the primary customer seg-
ments for Java Jolt
•Marketing Strategy including pricing decisions, promotional ac-
tivities, and ways to diﬀerentiate Java Jolt from competitors
•Implementation Plan detailing the actions necessary to launch
Java Jolt successfully
•Budgetallocatingfundstoeachcomponentofthemarketingplan
Acomprehensivemarketingplanhasbeendevelopedbasedonexten-
siveresearchintothelocalmarketconditions,consumertrends,and
competitivelandscape. Withitsuniquecombinationofpremiumcof-
feedrinksandwirelessInternetaccess,JavaJoltwillquicklybecome
a favorite destination for people seeking a relaxing environment to
socialize, study, or conduct business.Here’s a marketing plan for your local coﬀee shop.
Marketing Goals and Objectives
•Increase awareness of our brand among consumers [...]
•Drive foot traﬃc [...] during slow business hours [...]
•Build relationships with inﬂuencers in our community who [...]
Deﬁne Target Audience
Our target audiences include:
•Residents of the neighborhood surrounding our coﬀee shop
•Oﬃce workers near our coﬀee shop
•Students at nearby schools
Wewillfocusourmarketingeﬀortsontheseaudiencesbecausethey
are most likely to become regular customers at our [...]
Research Marketing Tactics
Here are some marketing tactics that we could use to reach to reach
our target audiences and achieve our goals:
•Hosteventsatourcoﬀeeshopthatappealtoourtargetaudiences
(e.g., open mic nights for students or networking events [...]
•Oﬀer discounts during slow business hours to entice [...]
•[...]
Plan Marketing Tactics
Here’s how we will implement the marketing tactics above:
•Events: Wewillhostoneeventpermonthatourcoﬀeeshop. For
each event, we will send out email invitations [...]
•Discounts: EveryMondaythroughThursdayfrom3pm–6pm,we
will oﬀer $1 oﬀ any drink purchase. To promote [...]
•Localpartnerships: Wewillreachouttoﬁvelocalbusinessesand
schools to ask if we can leave stacks of coupons [...]
•Social media: [...]
•Reviews: [...]
Develop Your Timeline and Budget
This is what our marketing timeline looks like:
•Month 1: Launch email newsletter and social media accounts
•Month 2: Start distributing coupons at [...]
•[...]
Here’s the budget for each marketing activity:
•Email newsletter: $50/month for MailChimp subscription
•Social media: $100/month for paid ads [...]
•[...]
[Summarization into Bullet Points (In Distribution)]
Can you summarize this message into bullet points? Gradually slowing job gains and a growing labor force in March [...] Mr. Biden
said [...]. More Americans joined the labor force, [...] this spring that he will seek re-election.
Though the unemployment rate fell to its lowest level since May
1970, at 4.8 percent, Mr. Biden still faces an economy that leaves
many Americans feeling left behind. Many working-class [...]
Mr. Biden’s challenge will be persuading those voters that the eco-
nomic picture has [...] His opponents have already begun painting
a bleak portrait of the economy, arguing that most Americans have
not beneﬁted from the president’s policies.
“The March jobs report shows continued solid job growth but also
indicates that we must do better,” said Representative Nancy Pelosi
of California, the Democratic leader in the House. [...]Here are the main points from the text:
•Jobcreationslowedto236,000forthemonthofMarch,whichis
close to the level needed to stabilize the economy and prices.
•More Americans joined the labor force, and wage gains fell
slightly, both of which should help cool inﬂation.
•The report underscores the political tensions facing President
Biden ahead of his expected announcement that he will seek re-
election.
Figure 13: Model outputs from test prompts that ask the model to generate according to speciﬁed
structures. The gray ellipsis [...] indicates that the response was trimmed to ﬁt this page, but the
generated text is actually longer.
15