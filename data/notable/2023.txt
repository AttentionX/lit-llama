Track Anything: Segment Anything Meets Videos,24 Apr 2023,https://arxiv.org/pdf/2304.11968
Scaling Transformer to 1M tokens and beyond with RMT,19 Apr 2023,https://arxiv.org/pdf/2304.11062
LIMA: Less Is More for Alignment,18 May 2023,https://arxiv.org/pdf/2305.11206
Tree of Thoughts: Deliberate Problem Solving with Large Language Models,17 May 2023,https://arxiv.org/pdf/2305.10601
Causal Reasoning and Large Language Models: Opening a New Frontier for Causality,28 Apr 2023,https://arxiv.org/pdf/2305.00050
AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head,25 Apr 2023,https://arxiv.org/pdf/2304.12995
CodeT5+: Open Code Large Language Models for Code Understanding and Generation,13 May 2023,https://arxiv.org/pdf/2305.07922
Shap-E: Generating Conditional 3D Implicit Functions,3 May 2023,https://arxiv.org/pdf/2305.02463
Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes,3 May 2023,https://arxiv.org/pdf/2305.02301,ACL 2023
Unlimiformer: Long-Range Transformers with Unlimited Length Input,2 May 2023,https://arxiv.org/pdf/2305.01625