{"question": "What is the main contribution of GPT-4?", "answer": "The main contribution of GPT-4 is a large-scale, multimodal model capable of accepting image and text inputs and producing text outputs."}
{"question": "What benchmarks did GPT-4 perform well on?", "answer": "GPT-4 performed well on professional and academic benchmarks, including passing a simulated bar exam with a score in the top 10% of test takers."}
{"question": "What are the limitations of GPT-4?", "answer": "GPT-4 is not fully reliable, can suffer from 'hallucinations', has a limited context window, and does not learn from experience. Care should be taken when using its outputs, especially in contexts where reliability is important."}
{"question": "What were the key challenges in developing GPT-4?", "answer": "One key challenge in developing GPT-4 was building a deep learning stack that scales predictably. Infrastructure and optimization methods were developed to have predictable behavior across different scales, allowing accurate predictions of GPT-4's performance based on smaller models."}
{"question": "How did GPT-4\u2019s performance compare to previous large language models?", "answer": "GPT-4 outperformed previous large language models and most state-of-the-art systems on traditional NLP benchmarks. It exhibited human-level performance on various professional and academic exams."}
{"question": "What safety challenges does GPT-4 present?", "answer": "GPT-4's capabilities and limitations create significant and novel safety challenges. The report discusses risks related to bias, disinformation, over-reliance, privacy, cybersecurity, and proliferation. Interventions, such as adversarial testing and a model-assisted safety pipeline, were made to mitigate potential harms of GPT-4's deployment."}
{"question": "What is the scope of this technical report?", "answer": "This technical report focuses on the capabilities, limitations, and safety properties of GPT-4. It provides details about the model's performance on various benchmarks and exams, as well as the challenges and methodology in its development. However, it does not provide specific information on the architecture, model size, hardware, training compute, or dataset construction."}
{"question": "How was GPT-4 evaluated?", "answer": "GPT-4 was evaluated on a variety of benchmarks and exams, including simulated versions of exams designed for humans. The model's performance was compared to that of previous large language models and state-of-the-art systems. GPT-4 exhibited human-level performance on most of the exams tested, including passing a simulated bar exam with a score in the top 10% of test takers."}
{"question": "What are the implications of GPT-4's performance on professional and academic exams?", "answer": "GPT-4's performance on professional and academic exams demonstrates its capabilities in understanding and generating natural language text. It outperformed previous models and achieved human-level performance on most of the exams tested, including the simulated bar exam, LSAT, SAT, GRE, and various AP exams."}
{"question": "What were the results of GPT-4 on the simulated bar exam?", "answer": "GPT-4 scored 298 out of 400 on the simulated bar exam, which puts it in the top 10% of test takers."}
